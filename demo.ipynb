{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import duplicate_utils as du\n",
    "import imutils\n",
    "\n",
    "## read all the png images\n",
    "img_path = r\"C:\\TUC_study\\kopernikus\\dataset\\*.*\"\n",
    "\n",
    "im_ls = []\n",
    "for file in glob.glob(img_path):\n",
    "    img = cv2.imread(file)\n",
    "    im_ls.append(img)\n",
    "    # break\n",
    "\n",
    "\n",
    "# im_ls = im_ls[:20]\n",
    "# cv2.imshow(\"Zeros matx\", im_ls[0]) # show numpy array\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# idx = np.random.randint(0, len(im_ls)-1)\n",
    "# im_arr = im_ls[idx]\n",
    "# img = Image.fromarray(im_arr)\n",
    "# display(img), im_ls[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = du.preprocess_image_change_detection(im_arr, [1,3,5])\n",
    "# display(Image.fromarray( gray)), gray.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgray = cv2.cvtColor(im_arr, cv2.COLOR_BGR2GRAY)\n",
    "# ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "# contours= cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "#                             cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = imutils.grab_contours(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret, thresh = cv2.threshold(imgray, 127, 255,cv2.THRESH_BINARY)\n",
    "# Image.fromarray(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt_lens = [len(c) for c in cnts]\n",
    "# max_cnt_id = cnt_lens.index(max(cnt_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont_im = cv2.drawContours(thresh, [cnts[max_cnt_id]], 0, (0,255,0), 5)\n",
    "# Image.fromarray(cont_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = 0\n",
    "# res_cnts = []\n",
    "# max_area = 0\n",
    "# for c in cnts:\n",
    "    \n",
    "#     if cv2.contourArea(c) < 100:\n",
    "#         continue\n",
    "    \n",
    "#     if cv2.contourArea(c) > max_area:\n",
    "#         max_area = cv2.contourArea(c)\n",
    "#     res_cnts.append(c)\n",
    "#     score += cv2.contourArea(c)\n",
    "\n",
    "# max_area, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import cv2\n",
    "import duplicate_utils as du\n",
    "# from PIL import Image\n",
    "\n",
    "## read all the png images\n",
    "# img_path = r\"C:\\TUC_study\\kopernikus\\dataset\\*.*\"\n",
    "img_path = r\"C:\\TUC_study\\kopernikus\\imgs\"\n",
    "\n",
    "\n",
    "new_im_size = (500, 500)\n",
    "corrupt_files = []\n",
    "file_name_ls = []\n",
    "im_arr_ls = []\n",
    "\n",
    "if len(os.listdir(img_path)) != 0: \n",
    "    for file in os.listdir(img_path):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            try:\n",
    "                im_arr = cv2.imread(os.path.join(img_path,file))\n",
    "                im_resized = cv2.resize(im_arr, \n",
    "                                        new_im_size, \n",
    "                                        interpolation = cv2.INTER_AREA)\n",
    "                im_arr_ls.append(im_resized)\n",
    "                file_name_ls.append(file)\n",
    "            except cv2.error as e:\n",
    "                print(f\"Error opening file: {file}\")\n",
    "                corrupt_files.append(file)\n",
    "    if len(file_name_ls) == 0:\n",
    "        warnings.warn(\"No '.png' or '.jpg' files found in the folder\", UserWarning)\n",
    "else:\n",
    "    warnings.warn(\"The image folder is EMPTY!\", UserWarning)\n",
    "\n",
    "if len(file_name_ls) >= 2:\n",
    "    unique_ls = [file_name_ls[0]]\n",
    "    for i, _ in enumerate(im_arr_ls[:-1]):\n",
    "        gray1 = du.preprocess_image_change_detection(im_arr_ls[i], [3,5,7])\n",
    "        gray2 = du.preprocess_image_change_detection(im_arr_ls[i+1], [3,5,7])    \n",
    "        score, res_cnts, thresh = du.compare_frames_change_detection(gray1, gray2, 10000)\n",
    "        if score != 0:\n",
    "            unique_ls.append(file_name_ls[i+1])\n",
    "\n",
    "len(unique_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import concurrent.futures\n",
    "\n",
    "def read_image(image_path):\n",
    "    return cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "def read_images_parallel(image_paths):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        image_files = executor.map(read_image, image_paths)\n",
    "    return list(image_files)\n",
    "\n",
    "# Example usage\n",
    "image_paths = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\"]\n",
    "images = read_images_parallel(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_set = {1, 2, 3, 4, 5}\n",
    "my_set.discard(3)\n",
    "\n",
    "# Trying to discard an element not present in the set\n",
    "my_set.discard(6)\n",
    "my_set.discard(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(im_arr_ls))\n",
    "gray1 = du.preprocess_image_change_detection(im_arr_ls[502], [3,5,7])\n",
    "gray2 = du.preprocess_image_change_detection(im_arr_ls[500], [3,5,7])\n",
    "display(Image.fromarray(gray1)), display(Image.fromarray(gray2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_frames_change_detection(prev_frame, next_frame, min_contour_area):\n",
    "#     frame_delta = cv2.absdiff(prev_frame, next_frame)\n",
    "#     thresh = cv2.threshold(frame_delta, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "#     thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "#     cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "#                             cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "#     score = 0\n",
    "#     res_cnts = []\n",
    "#     for c in cnts:\n",
    "#         if cv2.contourArea(c) < min_contour_area:\n",
    "#             continue\n",
    "\n",
    "#         res_cnts.append(c)\n",
    "#         score += cv2.contourArea(c)\n",
    "\n",
    "#     return score, res_cnts, thresh, frame_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score, res_cnts, thresh, frame_delta = compare_frames_change_detection(gray1, gray2, 5000)\n",
    "# score, len(res_cnts)\n",
    "\n",
    "# cv2.drawContours(thresh, res_cnts, -1, (128,0,255),5)\n",
    "  \n",
    "# cv2.imshow('Contours', thresh)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ls = [file_name_ls[0]]\n",
    "for i, _ in enumerate(im_arr_ls[:-1]):\n",
    "    gray1 = du.preprocess_image_change_detection(im_arr_ls[i], [3,5,7])\n",
    "    gray2 = du.preprocess_image_change_detection(im_arr_ls[i+1], [3,5,7])    \n",
    "    score, res_cnts, thresh = du.compare_frames_change_detection(gray1, gray2, 2000)\n",
    "    if score != 0:\n",
    "        unique_ls.append(file_name_ls[i+1])\n",
    "\n",
    "len(unique_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Hashmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "def find_similar_images(folder_path, threshold=5):\n",
    "    image_hashes = {}\n",
    "    similar_images = set()\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Open the image file using PIL\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    # Compute the image hash using the average hashing algorithm\n",
    "                    img_hash = imagehash.average_hash(img)\n",
    "                    if img_hash in image_hashes:\n",
    "                        # If a similar image hash is found, add it to the similar_images set\n",
    "                        similar_images.add(image_hashes[img_hash])\n",
    "                        similar_images.add(filename)\n",
    "                    else:\n",
    "                        # Store the image hash in the dictionary\n",
    "                        image_hashes[img_hash] = filename\n",
    "            except OSError:\n",
    "                print(f\"Error opening file: {file_path}\")\n",
    "\n",
    "    # Remove similar images from the unique set\n",
    "    unique_images = set(os.listdir(folder_path)) - similar_images\n",
    "    return unique_images,similar_images\n",
    "\n",
    "# Example usage\n",
    "folder_path = r\"C:\\TUC_study\\kopernikus\\dataset\"\n",
    "\n",
    "unique_images, similar_images = find_similar_images(folder_path)\n",
    "print(\"Unique images:\")\n",
    "for image in unique_images:\n",
    "    print(image)\n",
    "\n",
    "len(similar_images), len(unique_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening file: c21_2021_03_27__10_36_36.png\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import cv2\n",
    "import duplicate_utils as du\n",
    " \n",
    "## read all the png images\n",
    "img_path = r\"C:\\TUC_study\\kopernikus\\dataset\"\n",
    "# img_path = r\"C:\\TUC_study\\kopernikus\\imgs\"\n",
    "all_filenames = os.listdir(img_path)\n",
    "\n",
    "def similarity_score(image_1, image_2, tolerance):\n",
    "    gray1 = du.preprocess_image_change_detection(image_1, [3,5,7])\n",
    "    gray2 = du.preprocess_image_change_detection(image_2, [3,5,7])    \n",
    "    sim_score, _, _ = du.compare_frames_change_detection(gray1, gray2, tolerance)\n",
    "    \n",
    "    return sim_score\n",
    "\n",
    "new_im_size = (500, 500)\n",
    "corrupt_files = []\n",
    "file_name_ls = []\n",
    "im_arr_ls = []\n",
    "\n",
    "if len(os.listdir(img_path)) == 0:\n",
    "    warnings.warn(\"The image folder is EMPTY!\", UserWarning)\n",
    "    # return\n",
    "\n",
    "for file in os.listdir(img_path):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "        try:\n",
    "            im_arr = cv2.imread(os.path.join(img_path,file))\n",
    "\n",
    "            # an image should be readable and at least 64x64\n",
    "            if im_arr is None:\n",
    "                print(f\"Error opening file: {file}\")\n",
    "                continue\n",
    "            if im_arr.size < 4096:\n",
    "                continue\n",
    "\n",
    "            im_resized = cv2.resize(im_arr, \n",
    "                                    new_im_size, \n",
    "                                    interpolation = cv2.INTER_AREA)\n",
    "            im_arr_ls.append(im_resized)\n",
    "            file_name_ls.append(file)\n",
    "        except cv2.error as e:\n",
    "            print(f\"Error opening file: {file}\")\n",
    "            corrupt_files.append(file)\n",
    "if len(file_name_ls) == 0:\n",
    "    warnings.warn(\"No '.png' or '.jpg' files found in the folder\", UserWarning)\n",
    "    #return\n",
    "\n",
    "\n",
    "contour_threshold = 2500\n",
    "unique_im_arr_ls = []\n",
    "similarity_dict = {'min_are_threshold': contour_threshold,\n",
    "                   'unique_image_files': [],\n",
    "                   'duplicate_image_files': [],\n",
    "                   }\n",
    "\n",
    "for idx, filename in enumerate(file_name_ls):\n",
    "    print(\"### checking similar image frames...\")\n",
    "    is_similar = False\n",
    "\n",
    "    ## check with previous image\n",
    "    if idx >= 1: \n",
    "        sim_score = similarity_score(im_arr_ls[idx], \n",
    "                                     im_arr_ls[idx-1], \n",
    "                                     contour_threshold)\n",
    "        if sim_score == 0:\n",
    "            is_similar = True\n",
    "            similarity_dict['duplicate_image_files'].append(filename)\n",
    "            continue   \n",
    "    \n",
    "    ## check with all unique images\n",
    "    for uniq_im in unique_im_arr_ls:\n",
    "        sim_score = similarity_score(im_arr_ls[idx], \n",
    "                                     uniq_im, \n",
    "                                     contour_threshold)\n",
    "        if sim_score == 0:\n",
    "            is_similar = True\n",
    "            similarity_dict['duplicate_image_files'].append(filename)\n",
    "            break\n",
    "\n",
    "    if not is_similar:\n",
    "        unique_im_arr_ls.append(im_arr_ls[idx])\n",
    "        similarity_dict['unique_image_files'].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "print(len(similarity_dict['duplicate_image_files']))\n",
    "print(len(similarity_dict['unique_image_files']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = img_path + '/unique'\n",
    "for i, im_file in enumerate(similarity_dict['unique_image_files']):\n",
    "    im = cv2.imread(os.path.join(img_path, im_file))\n",
    "    cv2.imwrite(os.path.join(path1, im_file), im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
